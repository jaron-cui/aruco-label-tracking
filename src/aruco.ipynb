{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-05T15:02:56.566761Z",
     "start_time": "2025-03-05T15:02:56.560995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import typing\n",
    "\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "code = 3\n",
    "marker = aruco.generateImageMarker(aruco_dict, code, 120, borderBits=1)\n",
    "cv2.imwrite(f'aruco{code}.png', marker)\n",
    "# cv2.imshow('image', marker)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add_margin(image, top, bottom, left, right, color=(0,0,0)):\n",
    "    \"\"\"Adds margin to an image.\n",
    "\n",
    "    Args:\n",
    "        image: A NumPy array representing the image.\n",
    "        top: Margin size at the top.\n",
    "        bottom: Margin size at the bottom.\n",
    "        left: Margin size at the left.\n",
    "        right: Margin size at the right.\n",
    "        color: Color of the margin (default: black).\n",
    "\n",
    "    Returns:\n",
    "        A new NumPy array with the added margin.\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    new_height = height + top + bottom\n",
    "    new_width = width + left + right\n",
    "\n",
    "    if image.ndim == 3:\n",
    "      new_image = np.zeros((new_height, new_width, image.shape[2]), dtype=image.dtype)\n",
    "      new_image[:] = color\n",
    "      new_image[top:top+height, left:left+width, :] = image\n",
    "    else:\n",
    "      new_image = np.zeros((new_height, new_width), dtype=image.dtype)\n",
    "      new_image[:] = color[0]\n",
    "      new_image[top:top+height, left:left+width] = image\n",
    "    return new_image\n",
    "\n",
    "image = cv2.imread('fiducial-test.jpg')\n",
    "image = (image.astype(np.int16)).clip(0, 255).astype(np.uint8)\n",
    "image = cv2.resize(image, (image.shape[1] // 4, image.shape[0] // 4), interpolation=cv2.INTER_AREA)\n",
    "# image = cv2.rotate(image, 2)\n",
    "# cv2.imshow('image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# image = np.expand_dims(marker, axis=2).repeat(3, axis=2)\n",
    "# image = add_margin(image, 50, 50, 50, 50, (255,255,255))\n",
    "# print(image.min())\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "parameters =  aruco.DetectorParameters()\n",
    "detector = aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "# Detect ArUco markers\n",
    "markerCorners, markerIds, rejectedCandidates = detector.detectMarkers(gray)\n",
    "\n",
    "# Draw bounding boxes around the detected markers\n",
    "if markerIds is not None:\n",
    "    for i in range(len(markerIds)):\n",
    "        corners = markerCorners[i].astype(\"int\")\n",
    "        cv2.polylines(image, [corners], True, (0, 255, 0), 2)\n",
    "        cv2.putText(image, str(markerIds[i][0]), (corners[0][0, 0], corners[0][0, 1] - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the image with detected markers\n",
    "    cv2.imshow('Detected ArUco Markers', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No ArUco markers detected in the image.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-05T16:47:20.555576Z",
     "start_time": "2025-03-05T16:47:08.590551Z"
    }
   },
   "id": "f3b09432e779ef47",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing frames: 41\n",
      "(960, 720, 3)\n"
     ]
    }
   ],
   "source": [
    "from arucosort import Sort\n",
    "from functorch import einops\n",
    "import torch\n",
    "import decord\n",
    "import numpy as np\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import typing\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "def video_frames_extractor(video_path: Path):\n",
    "  vr = decord.VideoReader(str(video_path), ctx=decord.cpu(0))\n",
    "  frames = []\n",
    "  for i in range(len(vr)):\n",
    "      frames.append(vr[i])\n",
    "  frames_tensor = torch.stack(frames)\n",
    "  frames_tensor = frames_tensor / 255.0\n",
    "  frames_tensor = einops.rearrange(frames_tensor, \"t h w c -> t c h w\")\n",
    "  # frames_tensor = NORMALIZER(frames_tensor)\n",
    "  return frames_tensor\n",
    "\n",
    "\n",
    "class TrackingAnnotator:\n",
    "  def __init__(self, aruco_dict: aruco.Dictionary, annotate_frame):\n",
    "    self.aruco_dict = aruco_dict\n",
    "    self.annotate_frame = annotate_frame\n",
    "    \n",
    "  def annotate_frames(self, frames: typing.List[np.ndarray]):\n",
    "    missing_frames = 0\n",
    "    mot_tracker = Sort(max_age=1000, min_hits=1, iou_threshold=0.3)\n",
    "    for frame in frames:\n",
    "      gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "      parameters =  aruco.DetectorParameters()\n",
    "      # parameters.cornerRefinementMethod = aruco.CORNER_REFINE_CONTOUR\n",
    "      # parameters.cornerRefinementMaxIterations = 5\n",
    "      detector = aruco.ArucoDetector(aruco_dict, parameters)\n",
    "      \n",
    "      # Detect ArUco markers\n",
    "      markerCorners, markerIds, rejectedCandidates = detector.detectMarkers(gray)\n",
    "      \n",
    "      detections = []\n",
    "      # Draw bounding boxes around the detected markers\n",
    "      if markerIds is not None:\n",
    "        detections = np.zeros((len(markerIds), 9))\n",
    "        for i in range(len(markerIds)):\n",
    "          corners = markerCorners[i].astype(\"int\").reshape((8,))\n",
    "          tracking_data = np.concatenate((corners, markerIds[i]))\n",
    "          detections[i] = tracking_data\n",
    "      else:\n",
    "        detections = np.zeros((0, 9))\n",
    "        missing_frames += 1\n",
    "          \n",
    "          # cv2.polylines(frame, [corners], True, (0, 255, 0), 2)\n",
    "          # cv2.putText(frame, str(markerIds[i][0]), (corners[0][0, 0], corners[0][0, 1] - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "      tracked = mot_tracker.update(detections)\n",
    "      unseen = {1, 2}\n",
    "      for tracker in tracked:\n",
    "        tracker = tracker.astype('int')\n",
    "        corners = tracker[:8].reshape((1, 4, 2))\n",
    "        # print('tracker:', tracker[-1])\n",
    "        cv2.polylines(frame, [corners], True, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, str(tracker[-1]), (corners[0][0, 0], corners[0][0, 1] - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        # cv2.putText(frame, str(tracker[-1]), (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 255, 0), 2)\n",
    "        unseen.remove(tracker[-1])\n",
    "      if 1 in unseen:\n",
    "        missing_frames += 1\n",
    "          \n",
    "    print('Missing frames: {}'.format(missing_frames))\n",
    "    \n",
    "\n",
    "def draw_marker(image: np.ndarray):\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  parameters =  aruco.DetectorParameters()\n",
    "  parameters.cornerRefinementMaxIterations = 2\n",
    "  detector = aruco.ArucoDetector(aruco_dict, parameters)\n",
    "  \n",
    "  # Detect ArUco markers\n",
    "  markerCorners, markerIds, rejectedCandidates = detector.detectMarkers(gray)\n",
    "  \n",
    "  # Draw bounding boxes around the detected markers\n",
    "  if markerIds is not None:\n",
    "      for i in range(len(markerIds)):\n",
    "          corners = markerCorners[i].astype(\"int\")\n",
    "          print(corners.shape)\n",
    "          cv2.polylines(image, [corners], True, (0, 255, 0), 2)\n",
    "          cv2.putText(image, str(markerIds[i][0]), (corners[0][0, 0], corners[0][0, 1] - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "  \n",
    "      # Display the image with detected markers\n",
    "      # cv2.imshow('Detected ArUco Markers', image)\n",
    "      # cv2.waitKey(0)\n",
    "      # cv2.destroyAllWindows()\n",
    "  else:\n",
    "      print(\"No ArUco markers detected in the image.\")\n",
    "  return image\n",
    "\n",
    "\n",
    "def label_frames(video_path: Path):\n",
    "  vr = decord.VideoReader(str(video_path), ctx=decord.cpu(0))\n",
    "  fps = vr.get_avg_fps()\n",
    "  frames = []\n",
    "  for i in range(len(vr)):\n",
    "    frame = cv2.cvtColor(vr[i].asnumpy(), cv2.COLOR_RGB2BGR)\n",
    "    # draw_marker(frame)\n",
    "    frames.append(frame)\n",
    "  annotator = TrackingAnnotator(aruco_dict, None)\n",
    "  annotator.annotate_frames(frames)\n",
    "  print(frames[0].shape)\n",
    "  # fourcc = cv2.VideoWriterProperties(*'mp4v')  # Codec for video encoding\n",
    "  video = cv2.VideoWriter('out.mp4', -1, fps, (frames[0].shape[1], frames[0].shape[0]))\n",
    "  for frame in frames:\n",
    "    video.write(frame)\n",
    "    \n",
    "  cv2.destroyAllWindows()\n",
    "  video.release()\n",
    "  \n",
    "label_frames(Path('../data/RGB_2025-03-05-14_58_10.mp4'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-07T20:46:29.629536Z",
     "start_time": "2025-03-07T20:46:27.397352Z"
    }
   },
   "id": "2d38e1b4010cd5e2",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 720, 3)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from arucosort import Sort\n",
    "from functorch import einops\n",
    "import torch\n",
    "import decord\n",
    "import numpy as np\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import typing\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "def video_frames_extractor(video_path: Path):\n",
    "  vr = decord.VideoReader(str(video_path), ctx=decord.cpu(0))\n",
    "  frames = []\n",
    "  for i in range(len(vr)):\n",
    "      frames.append(vr[i])\n",
    "  frames_tensor = torch.stack(frames)\n",
    "  frames_tensor = frames_tensor / 255.0\n",
    "  frames_tensor = einops.rearrange(frames_tensor, \"t h w c -> t c h w\")\n",
    "  # frames_tensor = NORMALIZER(frames_tensor)\n",
    "  return frames_tensor\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DetectionGap:\n",
    "  start_frame_index: int\n",
    "  start_corners: np.ndarray  # [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]\n",
    "  end_frame_index: int = None\n",
    "  end_corners: np.ndarray = None\n",
    "  \n",
    "  \n",
    "class TrackingAnnotator:\n",
    "  def __init__(self, aruco_dict: aruco.Dictionary, annotate_frame):\n",
    "    self.aruco_dict = aruco_dict\n",
    "    self.annotate_frame = annotate_frame\n",
    "    \n",
    "  def annotate_frames(self, frames: typing.List[np.ndarray]):\n",
    "    trajectory_breaks: typing.Dict[int, typing.List[DetectionGap]] = {}\n",
    "    last_trajectories: typing.Dict[int, DetectionGap] = {}\n",
    "    previous_corners = []\n",
    "    for frame_index, frame in enumerate(frames):\n",
    "      gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "      parameters =  aruco.DetectorParameters()\n",
    "      detector = aruco.ArucoDetector(aruco_dict, parameters)\n",
    "      \n",
    "      # Detect ArUco markers\n",
    "      markerCorners, markerIds, rejectedCandidates = detector.detectMarkers(gray)\n",
    "      \n",
    "      if markerIds is None:\n",
    "        markerIds = []\n",
    "      if markerCorners:\n",
    "        markerCorners, markerIds = markerCorners[0], markerIds[0]\n",
    "        \n",
    "      # record when detection for an aruco marker comes back online\n",
    "      for detection_index in range(len(markerIds)):\n",
    "        markerId = markerIds[detection_index]\n",
    "        corners = markerCorners[detection_index]\n",
    "        if markerId not in last_trajectories:  # TODO: rename the awfully named last_trajectories and tangential variables\n",
    "          continue\n",
    "        trajectory = last_trajectories[markerId]\n",
    "        trajectory.end_frame_index = frame_index\n",
    "        trajectory.end_corners = corners\n",
    "        if markerId not in trajectory_breaks:\n",
    "          trajectory_breaks[markerId] = []\n",
    "        trajectory_breaks[markerId].append(trajectory)\n",
    "        del last_trajectories[markerId]\n",
    "        \n",
    "      for markerId in [1, 2, 3]:\n",
    "        if markerId in markerIds or markerId in last_trajectories or markerId not in previous_corners:\n",
    "          continue\n",
    "        trajectory_break = DetectionGap(\n",
    "          frame_index - 1,\n",
    "          previous_corners[markerId]\n",
    "        )\n",
    "        last_trajectories[markerId] = trajectory_break\n",
    "      \n",
    "      previous_corners = {markerIds[i]: markerCorners[i] for i in range(len(markerIds))}\n",
    "      \n",
    "      # annotate the detected markers\n",
    "      for i, markerId in enumerate(markerIds):\n",
    "        self._annotate_frame(frame, markerId, markerCorners[i])\n",
    "        \n",
    "    self._annotate_gaps(frames, trajectory_breaks)\n",
    "  \n",
    "  def _annotate_gaps(self, frames: typing.List[np.ndarray], detection_gaps: typing.Dict[int, typing.List[DetectionGap]]):\n",
    "    \n",
    "    # for performance, first calculate all necessary optical flow frames\n",
    "    gray = [cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) for frame in frames]\n",
    "    optical_flow = [None] * len(frames)\n",
    "    for markerId, marker_detection_gaps in detection_gaps.items():\n",
    "      for detection_gap in marker_detection_gaps:\n",
    "        corners = detection_gap.start_corners.copy()\n",
    "        for frame_index in range(detection_gap.start_frame_index + 1, detection_gap.end_frame_index):\n",
    "          if optical_flow[frame_index] is not None:\n",
    "            continue\n",
    "          frame = frames[frame_index]\n",
    "          corners, st, err = cv2.calcOpticalFlowPyrLK(gray[frame_index - 1], gray[frame_index], corners, None)\n",
    "          corner_out_of_bounds = False\n",
    "          for corner_index, corner in enumerate(corners):\n",
    "            y, x = int(corner[0]), int(corner[1])\n",
    "            if not (0 <= y < frame.shape[0] and 0 <= x < frame.shape[1]):\n",
    "              corner_out_of_bounds = True\n",
    "              break\n",
    "          if corner_out_of_bounds:\n",
    "            continue\n",
    "          self._annotate_frame(frames[frame_index], markerId, corners)\n",
    "          \n",
    "    \n",
    "    # for markerId, marker_detection_gap in detection_gaps.items():\n",
    "    #   for detection_gap in marker_detection_gap:\n",
    "    #     corners = detection_gap.start_corners.copy()\n",
    "    #     for frame_index in range(detection_gap.start_frame_index + 1, detection_gap.end_frame_index):\n",
    "    #       # shift corners by corresponding optical flow value\n",
    "    #       corner_out_of_bounds = False\n",
    "    #       for corner_index, corner in enumerate(corners):\n",
    "    #         y, x = int(corner[0]), int(corner[1])  # we could technically be more precise and take weighted average of optical flow rather than casting indices to int\n",
    "    #         if not (0 <= y < optical_flow[frame_index].shape[0] and 0 <= x < optical_flow[frame_index].shape[1]):\n",
    "    #           corner_out_of_bounds = True\n",
    "    #           break\n",
    "    #         corner_movement = optical_flow[frame_index][y, x]\n",
    "    #         corners[corner_index] += corner_movement\n",
    "    #       if corner_out_of_bounds:\n",
    "    #         continue\n",
    "    #       self._annotate_frame(frames[frame_index], markerId, corners)\n",
    "    \n",
    "  def _annotate_frame(self, frame: np.ndarray, markerId: int, corners: np.ndarray):\n",
    "    corners = corners.astype(\"int\")\n",
    "    cv2.polylines(frame, [corners], True, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, str(markerId), (corners[0, 0], corners[0, 1] - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)  \n",
    "   \n",
    "\n",
    "def label_frames(video_path: Path):\n",
    "  vr = decord.VideoReader(str(video_path), ctx=decord.cpu(0))\n",
    "  fps = vr.get_avg_fps()\n",
    "  frames = []\n",
    "  for i in range(len(vr)):\n",
    "    frame = cv2.cvtColor(vr[i].asnumpy(), cv2.COLOR_RGB2BGR)\n",
    "    # draw_marker(frame)\n",
    "    frames.append(frame)\n",
    "  annotator = TrackingAnnotator(aruco_dict, None)\n",
    "  annotator.annotate_frames(frames)\n",
    "  print(frames[0].shape)\n",
    "  # fourcc = cv2.VideoWriterProperties(*'mp4v')  # Codec for video encoding\n",
    "  video = cv2.VideoWriter('out.mp4', -1, fps, (frames[0].shape[1], frames[0].shape[0]))\n",
    "  for frame in frames:\n",
    "    video.write(frame)\n",
    "    \n",
    "  cv2.destroyAllWindows()\n",
    "  video.release()\n",
    "  \n",
    "label_frames(Path('../data/RGB_2025-03-05-14_58_10.mp4'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T01:44:42.675797Z",
     "start_time": "2025-03-08T01:44:38.329107Z"
    }
   },
   "id": "95299dd3f69746c9",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c16fd708b6b9a95d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
