{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-08T03:55:02.220103Z",
     "start_time": "2025-03-08T03:54:57.597040Z"
    }
   },
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "code = 3\n",
    "marker = aruco.generateImageMarker(aruco_dict, code, 120, borderBits=1)\n",
    "cv2.imwrite(f'aruco{code}.png', marker)\n",
    "cv2.imshow('image', marker)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from arucosort import Sort\n",
    "from functorch import einops\n",
    "import torch\n",
    "import decord\n",
    "import numpy as np\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import typing\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "def video_frames_extractor(video_path: Path):\n",
    "  vr = decord.VideoReader(str(video_path), ctx=decord.cpu(0))\n",
    "  frames = []\n",
    "  for i in range(len(vr)):\n",
    "      frames.append(vr[i])\n",
    "  frames_tensor = torch.stack(frames)\n",
    "  frames_tensor = frames_tensor / 255.0\n",
    "  frames_tensor = einops.rearrange(frames_tensor, \"t h w c -> t c h w\")\n",
    "  # frames_tensor = NORMALIZER(frames_tensor)\n",
    "  return frames_tensor\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DetectionGap:\n",
    "  start_frame_index: int\n",
    "  start_corners: np.ndarray  # [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]\n",
    "  end_frame_index: int = None\n",
    "  \n",
    "  \n",
    "class TrackingAnnotator:\n",
    "  def __init__(self, aruco_dict: aruco.Dictionary, annotate_frame):\n",
    "    self.aruco_dict = aruco_dict\n",
    "    self.annotate_frame = annotate_frame\n",
    "    \n",
    "  def annotate_frames(self, frames: typing.List[np.ndarray]):\n",
    "    detections: typing.List[typing.Tuple[np.ndarray, np.ndarray]] = []\n",
    "    for frame_index, frame in enumerate(frames):\n",
    "      gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "      parameters =  aruco.DetectorParameters()\n",
    "      detector = aruco.ArucoDetector(aruco_dict, parameters)\n",
    "      \n",
    "      # Detect ArUco markers\n",
    "      marker_corners, marker_ids, rejectedCandidates = detector.detectMarkers(gray)\n",
    "      \n",
    "      if marker_ids is None:\n",
    "        marker_ids = []\n",
    "      if marker_corners:\n",
    "        marker_corners, marker_ids = marker_corners[0], marker_ids[0]\n",
    "        \n",
    "      detections.append((marker_corners, marker_ids))\n",
    "      \n",
    "      # annotate the detected markers\n",
    "      for i, marker_id in enumerate(marker_ids):\n",
    "        self._annotate_frame(frame, marker_id, marker_corners[i])\n",
    "    self._annotate_gaps(frames, detections)\n",
    "      \n",
    "  def find_detection_gaps(self, frames: typing.List[np.ndarray], detections: typing.List[typing.Tuple[np.ndarray, np.ndarray]]) -> typing.Dict[int, typing.List[DetectionGap]]:\n",
    "    # detection gaps for which a detected frame prior and detected frame after have been found\n",
    "    detection_gaps: typing.Dict[int, typing.List[DetectionGap]] = {}\n",
    "    # detection gaps preceded by a detected frame but for which detection has not yet resumed\n",
    "    unterminated_gaps: typing.Dict[int, DetectionGap] = {}\n",
    "    \n",
    "    previous_corners = []\n",
    "    for frame_index, frame in enumerate(frames):\n",
    "      # record when detection for an aruco marker comes back online\n",
    "      marker_corners, marker_ids = detections[frame_index]\n",
    "      for detection_index in range(len(marker_ids)):\n",
    "        marker_id = marker_ids[detection_index]\n",
    "        if marker_id not in unterminated_gaps:\n",
    "          continue\n",
    "        gap = unterminated_gaps[marker_id]\n",
    "        gap.end_frame_index = frame_index\n",
    "        if marker_id not in detection_gaps:\n",
    "          detection_gaps[marker_id] = []\n",
    "        detection_gaps[marker_id].append(gap)\n",
    "        del unterminated_gaps[marker_id]\n",
    "        \n",
    "      # record when detection for an aruco marker goes offline\n",
    "      for marker_id in [1, 2, 3]:\n",
    "        if marker_id in marker_ids or marker_id in unterminated_gaps or marker_id not in previous_corners:\n",
    "          continue\n",
    "        gap = DetectionGap(\n",
    "          frame_index - 1,\n",
    "          previous_corners[marker_id]\n",
    "        )\n",
    "        unterminated_gaps[marker_id] = gap\n",
    "      \n",
    "      previous_corners = {marker_ids[i]: marker_corners[i] for i in range(len(marker_ids))}\n",
    "      \n",
    "    # terminate any gaps for which detection never came back online\n",
    "    for marker_id, partial_gap in unterminated_gaps.items():\n",
    "      if marker_id not in detection_gaps:\n",
    "        detection_gaps[marker_id] = []\n",
    "      partial_gap.end_frame_index = len(frames)\n",
    "      detection_gaps[marker_id].append(partial_gap)\n",
    "      \n",
    "    return detection_gaps    \n",
    "  \n",
    "  def _annotate_gaps(self, frames: typing.List[np.ndarray], detections: typing.List[typing.Tuple[np.ndarray, np.ndarray]]):\n",
    "    forward_detection_gaps = self.find_detection_gaps(frames, detections)\n",
    "    backward_detection_gaps = self.find_detection_gaps(list(reversed(frames)), list(reversed(detections)))\n",
    "    \n",
    "    forward_interpolations = self._interpolated_marker_positions(frames, forward_detection_gaps)\n",
    "    backward_interpolations = self._interpolated_marker_positions(list(reversed(frames)), backward_detection_gaps)\n",
    "\n",
    "    combined_interpolation = {}\n",
    "    for marker_id in forward_interpolations:\n",
    "      forward_interpolation, backward_interpolation = forward_interpolations[marker_id], backward_interpolations[marker_id]\n",
    "      interpolation = [None] * len(frames)\n",
    "      for frame_index, (forward_corners, backward_corners) in enumerate(zip(forward_interpolation, reversed(backward_interpolation))):\n",
    "        if forward_corners is None and backward_corners is None:\n",
    "          continue\n",
    "        if forward_corners is None:\n",
    "          interpolation[frame_index] = backward_corners\n",
    "          continue\n",
    "        if backward_corners is None:\n",
    "          interpolation[frame_index] = forward_corners\n",
    "          continue\n",
    "        interpolation[frame_index] = (forward_corners + backward_corners) / 2\n",
    "      combined_interpolation[marker_id] = interpolation\n",
    "    missed = 0\n",
    "    for marker_id, interpolation in combined_interpolation.items():\n",
    "      for frame_index, corners in enumerate(interpolation):\n",
    "        if corners is None:\n",
    "          if marker_id == 1:\n",
    "            missed += 1\n",
    "          continue\n",
    "        self._annotate_frame(frames[frame_index], marker_id, corners)\n",
    "    \n",
    "  def _interpolated_marker_positions(self, frames: typing.List[np.ndarray], detection_gaps: typing.Dict[int, typing.List[DetectionGap]]) -> typing.Dict[int, typing.List[np.ndarray | None]]:\n",
    "\n",
    "    gray = [cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) for frame in frames]\n",
    "    interpolated_corners = {marker_id: [None] * len(frames) for marker_id in detection_gaps}\n",
    "    for marker_id, marker_detection_gaps in detection_gaps.items():\n",
    "      for detection_gap in marker_detection_gaps:\n",
    "        corners = detection_gap.start_corners.copy()\n",
    "        for frame_index in range(detection_gap.start_frame_index + 1, detection_gap.end_frame_index):\n",
    "          frame = frames[frame_index]\n",
    "          corners, st, err = cv2.calcOpticalFlowPyrLK(gray[frame_index - 1], gray[frame_index], corners, None)\n",
    "          if st.sum() != 4:\n",
    "            continue\n",
    "          corner_out_of_bounds = False\n",
    "          for corner_index, corner in enumerate(corners):\n",
    "            y, x = int(corner[0]), int(corner[1])\n",
    "            if not (0 <= y < frame.shape[1] and 0 <= x < frame.shape[0]):\n",
    "              corner_out_of_bounds = False\n",
    "              break\n",
    "          if corner_out_of_bounds:\n",
    "            continue\n",
    "          interpolated_corners[marker_id][frame_index] = corners\n",
    "    return interpolated_corners\n",
    "          \n",
    "    \n",
    "  def _annotate_frame(self, frame: np.ndarray, markerId: int, corners: np.ndarray):\n",
    "    corners = corners.astype(\"int\")\n",
    "    cv2.polylines(frame, [corners], True, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, str(markerId), (corners[0, 0], corners[0, 1] - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "def label_frames(video_path: Path):\n",
    "  vr = decord.VideoReader(str(video_path), ctx=decord.cpu(0))\n",
    "  fps = vr.get_avg_fps()\n",
    "  frames = []\n",
    "  for i in range(len(vr)):\n",
    "    frame = cv2.cvtColor(vr[i].asnumpy(), cv2.COLOR_RGB2BGR)\n",
    "    # draw_marker(frame)\n",
    "    frames.append(frame)\n",
    "  annotator = TrackingAnnotator(aruco_dict, None)\n",
    "  annotator.annotate_frames(frames)\n",
    "  # fourcc = cv2.VideoWriterProperties(*'mp4v')  # Codec for video encoding\n",
    "  video = cv2.VideoWriter('../out/out.mp4', -1, fps, (frames[0].shape[1], frames[0].shape[0]))\n",
    "  for frame in frames:\n",
    "    video.write(frame)\n",
    "    \n",
    "  cv2.destroyAllWindows()\n",
    "  video.release()\n",
    "  \n",
    "label_frames(Path('../data/RGB_2025-03-05-14_58_10.mp4'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T03:55:33.918750Z",
     "start_time": "2025-03-08T03:55:31.442317Z"
    }
   },
   "id": "95299dd3f69746c9",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c16fd708b6b9a95d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
